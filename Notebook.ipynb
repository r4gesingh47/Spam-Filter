{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0e574c",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cb202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing ,model_selection,neighbors,svm\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import xgboost, numpy, textblob, string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522dc677",
   "metadata": {},
   "source": [
    "# Data Preprocessing And Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422251a6",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7120ed9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam                                            message\n",
       "0        0  Go until jurong point, crazy.. Available only ...\n",
       "1        0                      Ok lar... Joking wif u oni...\n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3        0  U dun say so early hor... U c already then say...\n",
       "4        0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Datasets/spam.csv')\n",
    "df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\n",
    "category={\"ham\": 0, \"spam\":1}\n",
    "df[\"v1\"].replace(category, inplace=True)\n",
    "df.rename({\"v1\": \"is_spam\", \"v2\": \"message\"},axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69571c6",
   "metadata": {},
   "source": [
    "Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3729a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=df.iloc[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d231c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba6683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331fae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    s=re.sub(r'[^\\w\\s]', '',s)\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    tokens= word_tokenize(s)\n",
    "    cleaned = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(cleaned)\n",
    "df['message']=df['message'].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d7f48",
   "metadata": {},
   "source": [
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128d4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.message\n",
    "y=df.is_spam\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e17df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4768    watever reLation u built dis world thing remai...\n",
       "5541                                        Yeah jus rite\n",
       "3583    Hi 07734396839 IBH Customer Loyalty Offer The ...\n",
       "1221                                         Prakesh know\n",
       "1955      Aight Ill grab something eat text youre back mu\n",
       "                              ...                        \n",
       "4019                       University southern california\n",
       "2338                                      Alright see bit\n",
       "482                                       Watching tv lor\n",
       "4975                  You gorgeous keep pix cumming thank\n",
       "5285    URGENT You 1 week FREE membership 100000 Prize...\n",
       "Name: message, Length: 4179, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9067fed",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa70e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
    "tesing=tfidf_vect_ngram_chars.fit(X)\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9b18c",
   "metadata": {},
   "source": [
    "Saving the tfidf fit feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0829d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "087699c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tesing, open(\"feature.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9712051",
   "metadata": {},
   "source": [
    "Feature engineering usinb vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5086df5",
   "metadata": {},
   "source": [
    "# Defining The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d5d46",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6460a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf=xgboost.XGBClassifier(use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00bc5826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:36:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgboost on tfidf char level 0.9856424982053122\n"
     ]
    }
   ],
   "source": [
    "model=xg_clf.fit(xtrain_tfidf_ngram_chars,train_y)\n",
    "y_predict=xg_clf.predict(xtest_tfidf_ngram_chars)\n",
    "score=metrics.accuracy_score(test_y,y_predict)\n",
    "print(\"Xgboost on tfidf char level\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67e586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5afe8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c72e704",
   "metadata": {},
   "source": [
    "# testing for single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baa5bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input(s):\n",
    "    s=re.sub(r'[^\\w\\s]', '',s)\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    tokens= word_tokenize(s)\n",
    "    cleaned = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9dab203",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"WINNER As valued network customer selected receivea 900 prize reward To claim call 09061701461 Claim code KL341 Valid 12 hours\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "781e9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[clean_input(s)]\n",
    "tfidf_test= TfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
    "tfidf_test.fit(X)\n",
    "tf_test = tfidf_test.transform(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "64cddc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10436 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 210 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7f5c3371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.predict(tf_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0fee0",
   "metadata": {},
   "source": [
    "# Pickling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9313ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(regressor, open('model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
